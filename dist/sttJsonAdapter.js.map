{"version":3,"sources":["webpack:///webpack/bootstrap","webpack:///./packages/stt-adapters/generate-entities-ranges/index.js","webpack:///./packages/stt-adapters/bbc-kaldi/group-words-by-speakers.js","webpack:///./packages/stt-adapters/bbc-kaldi/index.js","webpack:///./packages/stt-adapters/autoEdit2/index.js","webpack:///./packages/stt-adapters/speechmatics/index.js","webpack:///./packages/stt-adapters/amazon-transcribe/group-words-by-speakers.js","webpack:///./packages/stt-adapters/amazon-transcribe/index.js","webpack:///./packages/stt-adapters/ibm/index.js","webpack:///./packages/stt-adapters/digital-paper-edit/index.js","webpack:///./packages/stt-adapters/create-entity-map/index.js","webpack:///./packages/stt-adapters/google-stt/index.js","webpack:///./packages/stt-adapters/index.js","webpack:///./packages/stt-adapters/digital-paper-edit/group-words-by-speakers.js"],"names":["installedModules","__webpack_require__","moduleId","exports","module","i","l","modules","call","m","c","d","name","getter","o","Object","defineProperty","enumerable","get","r","Symbol","toStringTag","value","t","mode","__esModule","ns","create","key","bind","n","object","property","prototype","hasOwnProperty","p","s","generateEntitiesRanges","words","wordAttributeName","position","map","word","result","start","end","confidence","text","offset","length","Math","random","toString","substring","groupWordsInParagraphsBySpeakers","segments","wordsWithSpeakers","currentSpeaker","speaker","results","paragraph","forEach","push","punct","trim","groupWordsBySpeaker","tmpWordsWithSpeakers","tmpSpeakerSegment","tmpSegment","find","seg","segEnd","duration","@type","@id","gender","findSegmentForWord","addSpeakerToEachWord","bbcKaldiToDraft","bbcKaldiJson","tmpWords","speakerSegmentation","retval","segmentation","test","join","groupWordsInParagraphs","speakerLabel","concat","draftJsContentBlockParagraph","type","data","entityRanges","autoEdit2ToDraft","autoEdit2Json","autoEditText","autoEditparagraph","autoEditLine","line","tmpWord","startTime","endTime","getSpeaker","speakers","speakerIdx","segmentStart","parseFloat","speechmaticsToDraft","speechmaticsJson","curatedWords","maxParagraphWords","newSpeaker","oldSpeaker","sentenceEnd","element","index","time","toLowerCase","replace","paragraphStart","findSpeakerForWord","start_time","end_time","firstMatchingSegment","speaker_label","speakerLabels","groupedWords","groupWordsBySpeakerLabel","w","assign","addSpeakerLabelToWords","getBestAlternativeForWord","alternatives","reduce","prev","current","normalizeWord","currentWord","bestAlternative","content","mapPunctuationItemsToWords","itemsToRemove","punctuation","previousWord","punctuationContent","_objectSpread","appendPunctuationToPreviousWord","filter","item","includes","amazonTranscribeToDraft","amazonTranscribeJson","items","speaker_labels","wordsWithRemappedPunctuation","speakerGroup","groupSpeakerWordsInParagraphs","normalizedWord","ibmToDraft","ibmJson","ibmWords","ibmSpeakers","ibmResults","normalisedResults","normalisedWords","timestamps","ibmWord","ibmNormalisedWordsWithSpeakers","draftJsParagraphsResults","ibmParagraph","lines","speakerSegments","segStart","from","to","findSpeakerSegmentForWord","digitalPaperEditToDraft","digitalPaperEditTranscriptJson","paragraphs","flatten","list","a","b","Array","isArray","createEntityMap","blocks","block","flatEntityRanges","entityMap","mutability","computeTimeInSeconds","startSecond","nanoSecond","seconds","sentences","sentence","transcript","nanos","gcpSttToDraft","gcpSttJson","__webpack_exports__","create_entity_map","sttJsonAdapter","transcriptData","sttJsonType","console","error","currentSegment","currentSegmentIndex","previousSegmentIndex","indexOf","addWordsToSpeakersParagraphs"],"mappings":"2BACA,IAAAA,EAAA,GAGA,SAAAC,EAAAC,GAGA,GAAAF,EAAAE,GACA,OAAAF,EAAAE,GAAAC,QAGA,IAAAC,EAAAJ,EAAAE,GAAA,CACAG,EAAAH,EACAI,GAAA,EACAH,QAAA,IAUA,OANAI,EAAAL,GAAAM,KAAAJ,EAAAD,QAAAC,IAAAD,QAAAF,GAGAG,EAAAE,GAAA,EAGAF,EAAAD,QA0DA,OArDAF,EAAAQ,EAAAF,EAGAN,EAAAS,EAAAV,EAGAC,EAAAU,EAAA,SAAAR,EAAAS,EAAAC,GACAZ,EAAAa,EAAAX,EAAAS,IACAG,OAAAC,eAAAb,EAAAS,EAAA,CAA0CK,YAAA,EAAAC,IAAAL,KAK1CZ,EAAAkB,EAAA,SAAAhB,GACA,oBAAAiB,eAAAC,aACAN,OAAAC,eAAAb,EAAAiB,OAAAC,YAAA,CAAwDC,MAAA,WAExDP,OAAAC,eAAAb,EAAA,cAAiDmB,OAAA,KAQjDrB,EAAAsB,EAAA,SAAAD,EAAAE,GAEA,GADA,EAAAA,IAAAF,EAAArB,EAAAqB,IACA,EAAAE,EAAA,OAAAF,EACA,KAAAE,GAAA,iBAAAF,QAAAG,WAAA,OAAAH,EACA,IAAAI,EAAAX,OAAAY,OAAA,MAGA,GAFA1B,EAAAkB,EAAAO,GACAX,OAAAC,eAAAU,EAAA,WAAyCT,YAAA,EAAAK,UACzC,EAAAE,GAAA,iBAAAF,EAAA,QAAAM,KAAAN,EAAArB,EAAAU,EAAAe,EAAAE,EAAA,SAAAA,GAAgH,OAAAN,EAAAM,IAAqBC,KAAA,KAAAD,IACrI,OAAAF,GAIAzB,EAAA6B,EAAA,SAAA1B,GACA,IAAAS,EAAAT,KAAAqB,WACA,WAA2B,OAAArB,EAAA,SAC3B,WAAiC,OAAAA,GAEjC,OADAH,EAAAU,EAAAE,EAAA,IAAAA,GACAA,GAIAZ,EAAAa,EAAA,SAAAiB,EAAAC,GAAsD,OAAAjB,OAAAkB,UAAAC,eAAA1B,KAAAuB,EAAAC,IAGtD/B,EAAAkC,EAAA,GAIAlC,IAAAmC,EAAA,sCChDeC,IAtBgB,SAACC,EAAOC,GACrC,IAAIC,EAAW,EAEf,OAAOF,EAAMG,IAAI,SAACC,GAChB,IAAMC,EAAS,CACbC,MAAOF,EAAKE,MACZC,IAAKH,EAAKG,IACVC,WAAYJ,EAAKI,WACjBC,KAAML,EAAKH,GACXS,OAAQR,EACRS,OAAQP,EAAKH,GAAmBU,OAChCrB,IAAKsB,KAAKC,SACPC,SAAS,IACTC,UAAU,IAKf,OAFAb,EAAWA,EAAWE,EAAKH,GAAmBU,OAAS,EAEhDN,yDCuFIW,MA/Gf,SAA0ChB,EAAOiB,GAM/C,OA2BF,SAA6BC,GAAmB,IAC1CC,EAAiBD,EAAkB,GAAGE,QACpCC,EAAU,GACZC,EAAY,CAAEtB,MAAO,GAAIS,KAAM,GAAIW,QAAS,IA0BhD,OAzBAF,EAAkBK,QAAQ,SAACnB,GAErBe,IAAmBf,EAAKgB,SAC1BE,EAAUtB,MAAMwB,KAAKpB,GACrBkB,EAAUb,MAAQL,EAAKqB,MAAQ,IAC/BH,EAAUF,QAAUD,IAKpBA,EAAiBf,EAAKgB,QAEtBE,EAAUb,KAAOa,EAAUb,KAAKiB,OAEhCL,EAAQG,KAAKF,IAEbA,EAAY,CAAEtB,MAAO,GAAIS,KAAM,GAAIW,QAAS,UAElCpB,MAAMwB,KAAKpB,GACrBkB,EAAUb,MAAQL,EAAKqB,MAAQ,OAInCJ,EAAQG,KAAKF,GAEND,EA1DQM,CAWjB,SAA8B3B,EAAOiB,GACnC,IAAMW,EAAuB,GAQ7B,OAPA5B,EAAMuB,QAAQ,SAACnB,GACb,IAyFuBgB,EAzFjBS,EA4DV,SAA4BzB,EAAMa,GAEhC,IAAMa,EAAab,EAASc,KAAK,SAACC,GAChC,IAAMC,EAASD,EAAI1B,MAAQ0B,EAAIE,SAE/B,OAAS9B,EAAKE,OAAS0B,EAAI1B,OAAWF,EAAKG,KAAO0B,IALV,YAQtC,IAAAH,EAGK,CACLK,QAAS,UAGTf,QAAS,CAAEgB,MAAO,MAAOC,OAAQ,MAI5BP,EA/EmBQ,CAAmBlC,EAAMa,GAEnDb,EAAKgB,SAuFkBA,EAvFUS,EAAkBT,SAwFtCiB,OAAS,IAAMjB,EAAQ,OAvFpCQ,EAAqBJ,KAAKpB,KAGrBwB,EAtBmBW,CAAqBvC,EAAOiB,EAASA,YCkFlDuB,EAtDS,SAAAC,GAAgB,IAElCC,EADErB,EAAU,GAEZsB,EAAsB,KAgD1B,YA3CI,IAAAF,EAAaG,QAMfF,EAAWD,EAAazC,WACpB,IAAAyC,EAAaI,eACfF,EAAsBF,EAAaI,gBAPrCH,EAAWD,EAAaG,OAAO5C,WAC3B,IAAAyC,EAAaG,OAAOC,eACtBF,EAAsBF,EAAaG,OAAOC,gBASlB,OAAxBF,EA1CyB,SAAA3C,GAAS,IAChCqB,EAAU,GACZC,EAAY,CAAEtB,MAAO,GAAIS,KAAM,IAiBnC,OAfAT,EAAMuB,QAAQ,SAAAnB,GAER,QAAQ0C,KAAK1C,EAAKqB,QACpBH,EAAUtB,MAAMwB,KAAKpB,GACrBkB,EAAUb,KAAKe,KAAKpB,EAAKqB,OACzBH,EAAUb,KAAOa,EAAUb,KAAKsC,KAAK,KACrC1B,EAAQG,KAAKF,GAEbA,EAAY,CAAEtB,MAAO,GAAIS,KAAM,MAE/Ba,EAAUtB,MAAMwB,KAAKpB,GACrBkB,EAAUb,KAAKe,KAAKpB,EAAKqB,UAItBJ,EAwBe2B,CAAuBN,GAEvB1B,EAAiC0B,EAAUC,IAG/CpB,QAAQ,SAACD,EAAWvD,GAGpC,QAAI,IAAAuD,EAAUtB,MAAM,GAAkB,CACpC,IAAIiD,EAAY,OAAAC,OAAWnF,GACC,OAAxB4E,IACFM,EAAe3B,EAAUF,SAG3B,IAAM+B,EAA+B,CACnC1C,KAAMa,EAAUb,KAChB2C,KAAM,YACNC,KAAM,CACJjC,QAAS6B,EACTjD,MAAOsB,EAAUtB,MACjBM,MAAOgB,EAAUtB,MAAM,GAAGM,OAI5BgD,aAAcvD,YAAuBuB,EAAUtB,MAAO,UAExDqB,EAAQG,KAAK2B,MAIV9B,GCfMkC,EA1BU,SAACC,GAAkB,IACpCnC,EAAU,GAsBhB,OAxD6B,SAACoC,GAAiB,IACzCpC,EAAU,GACZC,EAAY,CAAEtB,MAAO,GAAIS,KAAM,IA4BnC,OA1BAgD,EAAalC,QAAQ,SAACmC,GACpBA,EAAkBpC,UAAUC,QAAQ,SAACoC,GACnCA,EAAaC,KAAKrC,QAAQ,SAACnB,GAIzB,IAAMyD,EAAU,CACdpD,KAAML,EAAKK,KACXH,MAAOF,EAAK0D,UACZvD,IAAKH,EAAK2D,SAGR,QAAQjB,KAAK1C,EAAKK,OACpBa,EAAUtB,MAAMwB,KAAKqC,GACrBvC,EAAUb,KAAKe,KAAKpB,EAAKK,MACzBY,EAAQG,KAAKF,GAEbA,EAAY,CAAEtB,MAAO,GAAIS,KAAM,MAE/Ba,EAAUtB,MAAMwB,KAAKqC,GACrBvC,EAAUb,KAAKe,KAAKpB,EAAKK,aAM1BY,EAMmB2B,CADTQ,EAAc/C,MAGbc,QAAQ,SAACD,EAAWvD,GACpC,IAAMoF,EAA+B,CACnC1C,KAAMa,EAAUb,KAAKsC,KAAK,KAC1BK,KAAM,YACNC,KAAM,CACJjC,QAAO,OAAA8B,OAAUnF,GACjBiC,MAAOsB,EAAUtB,MACjBM,MAAOgB,EAAUtB,MAAM,GAAGM,OAI5BgD,aAAcvD,YAAuBuB,EAAUtB,MAAO,SAGxDqB,EAAQG,KAAK2B,KAIR9B,GCxDH2C,EAAa,SAAC1D,EAAO2D,GACzB,IAAK,IAAIC,KAAcD,EAAU,KACzB7C,EAAU6C,EAASC,GACnBC,EAAeC,WAAW9D,GAChC,GAAI6D,GAAgB/C,EAAQd,MAAQ6D,EAAe/C,EAAQb,IACzD,OAAOa,EAAQ9C,KAInB,MAAO,OAyGM+F,EAhDa,SAACC,GAAqB,IAfvBtE,EACnBuE,EAeAlD,EAAU,GA4ChB,OA5DyBrB,EAmBIsE,EAAiBtE,MAlBxCuE,EAAe,GACrBvE,EAAMuB,QAAQ,SAACnB,GACT,SAAS0C,KAAK1C,EAAK9B,OAA6B,GAApB8B,EAAK9B,KAAKqC,QAAqC,EAAtB4D,EAAa5D,QACpE4D,EAAaA,EAAa5D,OAAS,GAAGrC,KAAOiG,EAAaA,EAAa5D,OAAS,GAAGrC,KAAO8B,EAAK9B,KAC/FiG,EAAaA,EAAa5D,OAAS,GAAGuB,UAAYkC,WAAWG,EAAaA,EAAa5D,OAAS,GAAGuB,UAAYkC,WAAWhE,EAAK8B,WAAWpB,YAE1IyD,EAAa/C,KAAKpB,KAxCO,SAACJ,EAAOiE,EAAUO,GAAsB,IAIjEC,EAHEpD,EAAU,GACZC,EAAY,CAAEtB,MAAO,GAAIS,KAAM,GAAIW,QAAS,IAC5CsD,EAAaV,EAAWhE,EAAM,GAAGM,MAAO2D,GAExCU,GAAW,EAoBf,OAlBA3E,EAAMuB,QAAQ,SAACnB,KACbqE,EAAaT,EAAW5D,EAAKE,MAAO2D,MAEjBS,GAAepD,EAAUtB,MAAMW,OAAS6D,GAAqBG,KAC9ErD,EAAUF,QAAUsD,EACpBrD,EAAQG,KAAKF,GACboD,EAAaD,EAEbnD,EAAY,CAAEtB,MAAO,GAAIS,KAAM,KAEjCa,EAAUtB,MAAMwB,KAAKpB,GACrBkB,EAAUb,KAAKe,KAAKpB,EAAKqB,OACzBkD,IAAc,QAAQ7B,KAAK1C,EAAKqB,SAGlCH,EAAUF,QAAUsD,EACpBrD,EAAQG,KAAKF,GAEND,EAiDmB2B,CA7BnBuB,EAQapE,IAAI,SAACyE,EAASC,GAChC,MAAQ,CACNvE,MAAOsE,EAAQE,KACfvE,KAAM6D,WAAWQ,EAAQE,MAAQV,WAAWQ,EAAQ1C,WAAWpB,WAC/DN,WAAYoE,EAAQpE,WACpBJ,KAAMwE,EAAQtG,KAAKyG,cAAcC,QAAQ,SAAU,IACnDvD,MAAOmD,EAAQtG,KACfuG,MAAOA,KAKGP,EAAiBL,SACL9D,IAAI,SAACyE,GAC7B,MAAQ,CACNtE,MAAO8D,WAAWQ,EAAQE,MAC1BvE,IAAM6D,WAAWQ,EAAQE,MAAQV,WAAWQ,EAAQ1C,UACpD5D,KAAMsG,EAAQtG,QAIsD,KAEtDiD,QAAQ,SAACD,GAAc,IACjC2D,EAAiB3D,EAAUtB,MAAM,GAAGM,MACpC6C,EAA+B,CACnC1C,KAAMa,EAAUb,KAAKsC,KAAK,KAC1BK,KAAM,YACNC,KAAM,CACJjC,QAASE,EAAUF,QACnBpB,MAAOsB,EAAUtB,MACjBM,MAAO2E,GAIT3B,aAAcvD,YAAuBuB,EAAUtB,MAAO,UAExDqB,EAAQG,KAAK2B,KAGR9B,GC1GI6D,EAAqB,SAAC9E,EAAMa,GAAa,IAC9C6C,EAAYM,WAAWhE,EAAK+E,YAC5BpB,EAAUK,WAAWhE,EAAKgF,UAC1BC,EAAuBpE,EAASc,KAAK,SAACC,GAC1C,OAAO8B,GAAaM,WAAWpC,EAAImD,aAAepB,GAAWK,WAAWpC,EAAIoD,YAJ1B,YAMhD,IAAAC,EACK,MAEAA,EAAqBC,cAAcN,QAAQ,OAAQ,KAQjDrD,EAAsB,SAAC3B,EAAOuF,GAGzC,OAtCsC,SAACvF,GAAU,IAC3CwF,EAAe,GACjBrE,EAAiB,GAarB,OAZAnB,EAAMuB,QAAQ,SAACnB,GACTA,EAAKkF,gBAAkBnE,EACzBqE,EAAaA,EAAa7E,OAAS,GAAGX,MAAMwB,KAAKpB,IAEjDe,EAAiBf,EAAKkF,cAEtBE,EAAahE,KAAK,CAChBJ,QAAShB,EAAKkF,cACdtF,MAAO,CAAEI,QAIRoF,EAuBAC,CAPsB,SAACzF,EAAOiB,GACrC,OAAOjB,EAAMG,IAAI,SAAAuF,GAAC,OAAIjH,OAAOkH,OAAOD,EAAG,CAAEJ,cAAiBJ,EAAmBQ,EAAGzE,OAItD2E,CAAuB5F,EAAOuF,EAActE,wcC5BjE,IAUM4E,EAA4B,SAAAzF,GACvC,MAAI,cAAc0C,KAAK1C,EAAKgD,MACnB3E,OAAOkH,OAAOvF,EAAK0F,aAAa,GAAI,CAAEtF,WAAY,IAEzBJ,EAAK0F,aAAaC,OAAO,SACzDC,EACAC,GAEA,OAAO7B,WAAW4B,EAAKxF,YAAc4D,WAAW6B,EAAQzF,YACpDwF,EACAC,KAUFC,EAAgB,SAAAC,GACpB,IAAMC,EAAkBP,EAA0BM,GAElD,MAAO,CACL7F,MAAO8D,WAAW+B,EAAYhB,YAC9B5E,IAAK6D,WAAW+B,EAAYf,UAC5B3E,KAAM2F,EAAgBC,QACtB7F,WAAY4D,WAAWgC,EAAgB5F,cAgB9B8F,EAA6B,SAAAtG,GAAS,IAC3CuG,EAAgB,GAatB,OAZmBvG,EAAMG,IAAI,SAACC,EAAMyE,GAAU,MAE1B,gBAAdzE,EAAKgD,MACPmD,EAAc/E,KAAKqD,EAAQ,GAjBc,SAAC2B,EAAaC,GAC3D,IAAMC,EAAqBF,EAAYV,aAAa,GAAGO,QAEvD,OAAAM,EAAA,GACKF,EADL,CAEEX,aAAcW,EAAaX,aAAa3F,IAAI,SAAAuF,GAAC,OAAAiB,EAAA,GACxCjB,EADwC,CAE3CW,QAASX,EAAEW,SAhDgBjG,EAgDYsG,EA/CpCtG,EAAK4E,QAAQ,MAAO,OADI,IAAA5E,MA6DpBwG,CAAgCxG,EAFxBJ,EAAM6E,EAAQ,KAItBzE,IAIOyG,OAAO,SAACC,EAAMjC,GAC9B,OAAQ0B,EAAcQ,SAASlC,MA6EpBmC,EAhCiB,SAAAC,GAAwB,IAChD5F,EAAU,GACVqB,EAAWuE,EAAqB5F,QAAQ6F,MACxC3B,EAAgB0B,EAAqB5F,QAAQ8F,eAC7CC,EAA+Bd,EAA2B5D,GAyBhE,YAxBqD,IAAlB6C,EAjBC,SAACvF,EAAOuF,GAG5C,OAFuB5D,EAAoB3B,EAAOuF,GAE5BpF,IAAI,SAACkH,GACzB,MAAO,CACLrH,MAAOqH,EAAarH,MAAMG,IAAI+F,GAC9BzF,KAAM4G,EAAarH,MAAMG,IAAI,SAACuF,GAAD,OAAOG,EAA0BH,GAAGW,UACjEjF,QAASiG,EAAajG,WAaxBkG,CAA8BF,EAA8B7B,GA5CjC,SAAAvF,GAAS,IAChCqB,EAAU,GACZC,EAAY,CACdtB,MAAO,GACPS,KAAM,IAiBR,OAfAT,EAAMuB,QAAQ,SAACnB,GAAS,IAChBiG,EAAUR,EAA0BzF,GAAMiG,QAC1CkB,EAAiBrB,EAAc9F,GACjC,QAAQ0C,KAAKuD,IACf/E,EAAUtB,MAAMwB,KAAK+F,GACrBjG,EAAUb,KAAKe,KAAK6E,GACpBhF,EAAQG,KAAKF,GAEbA,EAAY,CAAEtB,MAAO,GAAIS,KAAM,MAE/Ba,EAAUtB,MAAMwB,KAAK+F,GACrBjG,EAAUb,KAAKe,KAAK6E,MAIjBhF,EAwBL2B,CACEoE,IAGc7F,QAAQ,SAACD,EAAWvD,GACpC,IAAMoF,EAA+B,CACnC1C,KAAMa,EAAUb,KAAKsC,KAAK,KAC1BK,KAAM,YACNC,KAAM,CACJjC,QAASE,EAAUF,QAAV,WAAA8B,OAAgC5B,EAAUF,SAA1C,OAAA8B,OAA+DnF,GACxEiC,MAAOsB,EAAUtB,MACjBM,MAAO8D,WAAW9C,EAAUtB,MAAM,GAAGM,QAIvCgD,aAAcvD,YAAuBuB,EAAUtB,MAAO,SAExDqB,EAAQG,KAAK2B,KAGR9B,GCnDMmG,EA5FI,SAAAC,GAAW,IAgDAC,EAAUC,EAnCRC,EACtBC,EAqEFC,GAtEwBF,EAsEgBH,EAAQpG,QAAQ,GAAGA,QArEzDwG,EAAoB,GAC1BD,EAAWrG,QAAQ,SAAAlB,GAEjBwH,EAAkBrG,KAAgCnB,EAAOyF,aAAa,GAAGiC,WAdzD5H,IAAI,SAAA6H,GACpB,MAAO,CACLvH,KAAMuH,EAAQ,GACd1H,MAAO0H,EAAQ,GACfzH,IAAKyH,EAAQ,SAmBVH,GA+DT,OA9BoC,SAACI,GACnC,IAAMC,EAA2B,GAoBjC,OAnBAD,EAA+B1G,QAAQ,SAAC4G,GACtC,IAAMhF,EAA+B,CACnC1C,KAAM0H,EAAahI,IAAI,SAACC,GAAU,OAAOA,EAAKK,OAAQsC,KAAK,KAC3DK,KAAM,YACNC,KAAM,CAIJjC,QAAS+G,EAAa,GAAG/G,QACzBpB,MAAOmI,EACP7H,MAAO6H,EAAa,GAAG7H,OAIzBgD,aAAcvD,YAAuBoI,EAAc,SAErDD,EAAyB1G,KAAK2B,KAGzB+E,EArB2B,EAXRR,EAsC8BI,EAtCpBH,EAsCqCF,EAAQpG,QAAQ,GAAG8F,eArCrFO,EAASvH,IAAI,SAAAiI,GAClB,OAAOA,EAAMjI,IAAI,SAAAC,GAIf,OAFAA,EAAKgB,QAtBuB,SAAChB,EAAMiI,GACvC,IAAMvG,EAAauG,EAAgBtG,KAAK,SAAAC,GAAO,IACvCsG,EAAWtG,EAAIuG,KACftG,EAASD,EAAIwG,GAEnB,OAASpI,EAAKE,QAAUgI,GAAclI,EAAKG,MAAQ0B,IALM,YAQvD,IAAAH,EAGK,MAXkD,KAAAoB,OAc5CpB,EAAWV,SAQPqH,CAA0BrI,EAAMuH,GAExCvH,iBCiBAsI,EA5CiB,SAACC,GAAmC,IAC5DtH,EAAU,GACZsB,EAAsB,KAEpBD,EAAWiG,EAA+B3I,MAqChD,OAnCI2I,EAA+BC,aACjCjG,EAAsBgG,EAA+BC,aAGlDjG,EAGiB3B,kBAAiC0B,EAAUiG,EAA+BC,YAnCnE,SAAA5I,GAAS,IAChCqB,EAAU,GACZC,EAAY,CAAEtB,MAAO,GAAIS,KAAM,IAiBnC,OAfAT,EAAMuB,QAAQ,SAAAnB,GAER,QAAQ0C,KAAK1C,EAAKK,OACpBa,EAAUtB,MAAMwB,KAAKpB,GACrBkB,EAAUb,KAAKe,KAAKpB,EAAKK,MACzBa,EAAUb,KAAOa,EAAUb,KAAKsC,KAAK,KACrC1B,EAAQG,KAAKF,GAEbA,EAAY,CAAEtB,MAAO,GAAIS,KAAM,MAE/Ba,EAAUtB,MAAMwB,KAAKpB,GACrBkB,EAAUb,KAAKe,KAAKpB,EAAKK,SAItBY,EAce2B,CAAuBN,IAK3BnB,QAAQ,SAACD,EAAWvD,GAGpC,GAAIuD,EAAUtB,MAAM,GAAI,CACtB,IAAIiD,EAAY,OAAAC,OAAWnF,GACvB4E,IACFM,EAAe3B,EAAUF,SAG3B,IAAM+B,EAA+B,CACnC1C,KAAMa,EAAUb,KAChB2C,KAAM,YACNC,KAAM,CACJjC,QAAS6B,EACTjD,MAAOsB,EAAUtB,MACjBM,MAAOgB,EAAUtB,MAAM,GAAGM,OAI5BgD,aAAcvD,YAAuBuB,EAAUtB,MAAO,SAExDqB,EAAQG,KAAK2B,MAIV9B,GClEHwH,EAAU,SAAAC,GAAI,OAAIA,EAAK/C,OAAO,SAACgD,EAAGC,GAAJ,OAAUD,EAAE7F,OAAO+F,MAAMC,QAAQF,GAAKH,EAAQG,GAAKA,IAAI,KAuB5EG,EAjBS,SAACC,GAAW,IAC5B9F,EAAe8F,EAAOjJ,IAAI,SAAAkJ,GAAK,OAAIA,EAAM/F,eACzCgG,EAAmBT,EAAQvF,GAE3BiG,EAAY,GAUlB,OARAD,EAAiB/H,QAAQ,SAAC8B,GACxBkG,EAAUlG,EAAK/D,KAAO,CACpB8D,KAAM,OACNoG,WAAY,UACZnG,UAIGkG,GCYHE,EAAuB,SAACC,EAAaC,GAEzC,IAAIC,EAAUxF,WAAWsF,GAMzB,YAJI,IAAAC,IACFC,GAAoBxF,WAAWuF,EAvCf,MA0CXC,GAqBH5G,EAAyB,SAAA6G,GAAa,IACpCxI,EAAU,GACZC,EAAY,CACdtB,MAAO,GACPS,KAAM,IAcR,OAXAoJ,EAAUtI,QAAQ,SAACuI,GACjB,IAhEsCD,EAgEhCzD,EA/D8B,KADEyD,EAgEaC,GA/DvChE,aAAanF,OAClBkJ,EAAU,GAGmBA,EAAU/D,aAAaC,OAAO,SAClEC,EACAC,GAEA,OAAO7B,WAAW4B,EAAKxF,YAAc4D,WAAW6B,EAAQzF,YACpDwF,EACAC,IAsDJ3E,EAAUb,KAAKe,KAAqC4E,EAAgB2D,WA/C1DrI,QAiDV0E,EAAgBpG,MAAMuB,QAAQ,SAACnB,GAzBb,IAAC+F,EAAa3F,EA0B9Bc,EAAUtB,MAAMwB,MA1BC2E,EA0BkB/F,EA1BLI,EA0BW4F,EAAgB5F,WAxBtD,CACLF,MAAOmJ,EAAqBtD,EAAYrC,UAAU8F,QAASzD,EAAYrC,UAAUkG,OACjFzJ,IAAKkJ,EAAqBtD,EAAYpC,QAAQ6F,QAASzD,EAAYpC,QAAQiG,OAC3EvJ,KAAM0F,EAAY/F,KAClBI,WAAYA,OAsBZa,EAAQG,KAAKF,GACbA,EAAY,CAAEtB,MAAO,GAAIS,KAAM,MAG1BY,GA6BM4I,EA1BO,SAAAC,GAAc,IAC5B7I,EAAU,GAsBhB,OAlB0B2B,EAAuBkH,EAAW7I,SAE1CE,QAAQ,SAACD,EAAWvD,GACpC,IAAMoF,EAA+B,CACnC1C,KAAMa,EAAUb,KAAKsC,KAAK,KAC1BK,KAAM,YACNC,KAAM,CACJjC,QAASE,EAAUF,QAAV,WAAA8B,OAAgC5B,EAAUF,SAA1C,OAAA8B,OAA+DnF,GACxEiC,MAAOsB,EAAUtB,MACjBM,MAAO8D,WAAW9C,EAAUtB,MAAM,GAAGM,QAIvCgD,aAAcvD,YAAuBuB,EAAUtB,MAAO,SAExDqB,EAAQG,KAAK2B,KAGR9B,GClHT1D,EAAAU,EAAA8L,EAAA,oCAAAC,IAwDeC,UA1CQ,SAACC,EAAgBC,GACtC,IAAInB,EACJ,OAAQmB,GACR,IAAK,WAGH,MAAO,CAAEnB,OAFTA,EAAS5G,EAAgB8H,GAERf,UAAWJ,EAAgBC,IAC9C,IAAK,YAGH,MAAO,CAAEA,OAFTA,EAAS7F,EAAiB+G,GAETf,UAAWJ,EAAgBC,IAC9C,IAAK,eAGH,MAAO,CAAEA,OAFTA,EAAS/E,EAAoBiG,GAEZf,UAAWJ,EAAgBC,IAC9C,IAAK,MAGH,MAAO,CAAEA,OAFTA,EAAS5B,EAAW8C,GAEHf,UAAWJ,EAAgBC,IAC9C,IAAK,UACH,OAAOkB,EAET,IAAK,mBAGH,MAAO,CAAElB,OAFTA,EAASpC,EAAwBsD,GAEhBf,UAAWJ,EAAgBC,IAC9C,IAAK,mBAGH,MAAO,CAAEA,OAFTA,EAASV,EAAwB4B,GAEhBf,UAAWJ,EAAgBC,IAE9C,IAAK,aAGH,MAAO,CAAEA,OAFTA,EAASa,EAAcK,GAENf,UAAWJ,EAAgBC,IAE9C,QAEEoB,QAAQC,MAAM,wECpDlB9M,EAAAkB,EAAAsL,GA4IenJ,UA9Df,SAA0ChB,EAAOiB,GAG/C,OAGF,SAAuCjB,EAAOiB,GAAU,IAChDI,EAAU,GACZqJ,EAAiB,MACjBC,EAAsB,EACtBC,EAAuB,EACvBtJ,EAAY,CAAEtB,MAAO,GAAIS,KAAM,GAAIW,QAAS,IAwBhD,OAvBApB,EAAMuB,QAAQ,SAACnB,IACbsK,EAsCJ,SAA4BtK,EAAMa,GAQhC,OANmBA,EAASc,KAAK,SAACC,GAChC,GAAK5B,EAAKE,OAAS0B,EAAI1B,OAAWF,EAAKG,KAAOyB,EAAIzB,IAChD,OAAOyB,IA1CQM,CAAmBlC,EAAMa,OAGxC0J,EAAsB1J,EAAS4J,QAAQH,MACXE,GAC1BtJ,EAAUtB,MAAMwB,KAAKpB,GACrBkB,EAAUb,MAAQL,EAAKK,KAAO,IAC9Ba,EAAUF,QAAUsJ,EAAetJ,UAGnCwJ,EAAuBD,EACvBrJ,EAAUb,KAAKiB,OACfL,EAAQG,KAAKF,IACbA,EAAY,CAAEtB,MAAO,GAAIS,KAAM,GAAIW,QAAS,KAClCpB,MAAMwB,KAAKpB,GACrBkB,EAAUb,MAAQL,EAAKK,KAAO,IAC9Ba,EAAUF,QAAUsJ,EAAetJ,YAIzCC,EAAQG,KAAKF,GAEND,EAlCQyJ,CAA6B9K,EAAOiB","file":"sttJsonAdapter.js","sourcesContent":[" \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId]) {\n \t\t\treturn installedModules[moduleId].exports;\n \t\t}\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, { enumerable: true, get: getter });\n \t\t}\n \t};\n\n \t// define __esModule on exports\n \t__webpack_require__.r = function(exports) {\n \t\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n \t\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n \t\t}\n \t\tObject.defineProperty(exports, '__esModule', { value: true });\n \t};\n\n \t// create a fake namespace object\n \t// mode & 1: value is a module id, require it\n \t// mode & 2: merge all properties of value into the ns\n \t// mode & 4: return value when already ns object\n \t// mode & 8|1: behave like require\n \t__webpack_require__.t = function(value, mode) {\n \t\tif(mode & 1) value = __webpack_require__(value);\n \t\tif(mode & 8) return value;\n \t\tif((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;\n \t\tvar ns = Object.create(null);\n \t\t__webpack_require__.r(ns);\n \t\tObject.defineProperty(ns, 'default', { enumerable: true, value: value });\n \t\tif(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));\n \t\treturn ns;\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(__webpack_require__.s = 39);\n","/**\r\n * Helper function to generate draft.js entities,\r\n * see unit test for example data structure\r\n * it adds offset and length to recognise word in draftjs\r\n */\r\n\r\n/**\r\n*  @param {json} words  - List of words\r\n*  @param {string} wordAttributeName - eg 'punct' or 'text' or etc.\r\n* attribute for the word object containing the text. eg word ={ punct:'helo', ... }\r\n*  or eg word ={ text:'helo', ... }\r\n*/\r\nconst generateEntitiesRanges = (words, wordAttributeName) => {\r\n  let position = 0;\r\n\r\n  return words.map((word) => {\r\n    const result = {\r\n      start: word.start,\r\n      end: word.end,\r\n      confidence: word.confidence,\r\n      text: word[wordAttributeName],\r\n      offset: position,\r\n      length: word[wordAttributeName].length,\r\n      key: Math.random()\r\n        .toString(36)\r\n        .substring(6),\r\n    };\r\n    // increase position counter - to determine word offset in paragraph\r\n    position = position + word[wordAttributeName].length + 1;\r\n\r\n    return result;\r\n  });\r\n};\r\n\r\nexport default generateEntitiesRanges;\r\n","/**\r\nedge cases\r\n- more segments then words - not an issue if you start by matching words with segment\r\nand handle edge case where it doesn't find a match\r\n- more words then segments - orphan words\r\n */\r\nfunction groupWordsInParagraphsBySpeakers(words, segments) {\r\n  // add speakers to each word\r\n  const wordsWithSpeakers = addSpeakerToEachWord(words, segments.segments);\r\n  // group words by speakers sequentially\r\n  const result = groupWordsBySpeaker(wordsWithSpeakers);\r\n\r\n  return result;\r\n};\r\n\r\n/**\r\n* Add speakers to each words\r\n* if it doesn't have add unknown attribute `U_UKN`\r\n* @param {*} words\r\n* @param {*} segments\r\n*/\r\nfunction addSpeakerToEachWord(words, segments) {\r\n  const tmpWordsWithSpeakers = [];\r\n  words.forEach((word) => {\r\n    const tmpSpeakerSegment = findSegmentForWord(word, segments);\r\n\r\n    word.speaker = formatSpeakerName(tmpSpeakerSegment.speaker);\r\n    tmpWordsWithSpeakers.push(word);\r\n  });\r\n\r\n  return tmpWordsWithSpeakers;\r\n}\r\n\r\n/**\r\n * Groups Words by speaker attribute\r\n * @param {array} wordsWithSpeakers - same as kaldi words list but with a `speaker` label attribute on each word\r\n * @return {array} - list of paragraph objcts, with words, text and sepaker attributes.\r\n * where words is an array and the other two are strings.\r\n */\r\nfunction groupWordsBySpeaker(wordsWithSpeakers) {\r\n  let currentSpeaker = wordsWithSpeakers[0].speaker;\r\n  const results = [ ];\r\n  let paragraph = { words: [], text: '', speaker: '' };\r\n  wordsWithSpeakers.forEach((word) => {\r\n    // if current speaker same as word speaker add words to paragraph\r\n    if (currentSpeaker === word.speaker) {\r\n      paragraph.words.push(word);\r\n      paragraph.text += word.punct + ' ';\r\n      paragraph.speaker = currentSpeaker;\r\n    }\r\n    // if it's not same speaker\r\n    else {\r\n      // update current speaker\r\n      currentSpeaker = word.speaker;\r\n      // remove spacing in text\r\n      paragraph.text = paragraph.text.trim();\r\n      //save  previous paragraph\r\n      results.push(paragraph);\r\n      // reset paragraph\r\n      paragraph = { words: [], text: '', speaker: 'U_UKN' };\r\n      // add words attributes to new\r\n      paragraph.words.push(word);\r\n      paragraph.text += word.punct + ' ';\r\n    }\r\n  });\r\n  // add last paragraph\r\n  results.push(paragraph);\r\n\r\n  return results;\r\n}\r\n\r\n/**\r\n* Helper functions\r\n*/\r\n\r\n/**\r\n* given word start and end time attributes\r\n* looks for segment range that contains that word\r\n* if it doesn't find any it returns a segment with `UKN`\r\n* speaker attributes.\r\n* @param {object} word - word object\r\n* @param {array} segments - list of segments objects\r\n* @return {object} - a single segment whose range contains the word\r\n*/\r\nfunction findSegmentForWord(word, segments) {\r\n\r\n  const tmpSegment = segments.find((seg) => {\r\n    const segEnd = seg.start + seg.duration;\r\n\r\n    return ((word.start >= seg.start) && (word.end <= segEnd));\r\n  });\r\n  // if find doesn't find any matches it returns an undefined\r\n  if (tmpSegment === undefined) {\r\n    // covering edge case orphan word not belonging to any segments\r\n    // adding UKN speaker label\r\n    return {\r\n      '@type': 'Segment',\r\n      // keeping both speaker id and gender as this is used later\r\n      // to format speaker label combining the two\r\n      speaker: { '@id': 'UKN', gender: 'U' }\r\n    };\r\n  } else {\r\n    // find returns the first element that matches the criteria\r\n    return tmpSegment;\r\n  }\r\n}\r\n\r\n/**\r\n* formats kaldi speaker object into a string\r\n* Combining Gender and speaker Id\r\n* @param {object} speaker - BBC kaldi speaker object\r\n* @return {string} -\r\n*/\r\nfunction formatSpeakerName(speaker) {\r\n  return speaker.gender + '_' + speaker['@id'];\r\n}\r\n\r\nexport default groupWordsInParagraphsBySpeakers;","/**\r\n * Convert BBC Kaldi json to draftJs\r\n * see `sample` folder for example of input and output as well as `example-usage.js`\r\n *\r\n */\r\n\r\nimport generateEntitiesRanges from '../generate-entities-ranges/index.js';\r\nimport groupWordsInParagraphsBySpeakers from './group-words-by-speakers.js';\r\n/**\r\n * groups words list from kaldi transcript based on punctuation.\r\n * @todo To be more accurate, should introduce an honorifics library to do the splitting of the words.\r\n * @param {array} words - array of words opbjects from kaldi transcript\r\n */\r\n\r\nconst groupWordsInParagraphs = words => {\r\n  const results = [];\r\n  let paragraph = { words: [], text: [] };\r\n\r\n  words.forEach(word => {\r\n    // if word contains punctuation\r\n    if (/[.?!]/.test(word.punct)) {\r\n      paragraph.words.push(word);\r\n      paragraph.text.push(word.punct);\r\n      paragraph.text = paragraph.text.join(' ');\r\n      results.push(paragraph);\r\n      // reset paragraph\r\n      paragraph = { words: [], text: [] };\r\n    } else {\r\n      paragraph.words.push(word);\r\n      paragraph.text.push(word.punct);\r\n    }\r\n  });\r\n\r\n  return results;\r\n};\r\n\r\nconst bbcKaldiToDraft = bbcKaldiJson => {\r\n  const results = [];\r\n  let tmpWords;\r\n  let speakerSegmentation = null;\r\n  let wordsByParagraphs = [];\r\n\r\n  // BBC Octo Labs API Response wraps Kaldi response around retval,\r\n  // while kaldi contains word attribute at root\r\n  if (bbcKaldiJson.retval !== undefined) {\r\n    tmpWords = bbcKaldiJson.retval.words;\r\n    if (bbcKaldiJson.retval.segmentation !== undefined) {\r\n      speakerSegmentation = bbcKaldiJson.retval.segmentation;\r\n    }\r\n  } else {\r\n    tmpWords = bbcKaldiJson.words;\r\n    if (bbcKaldiJson.segmentation !== undefined) {\r\n      speakerSegmentation = bbcKaldiJson.segmentation;\r\n    }\r\n  }\r\n\r\n  if (speakerSegmentation === null) {\r\n    wordsByParagraphs = groupWordsInParagraphs(tmpWords);\r\n  } else {\r\n    wordsByParagraphs = groupWordsInParagraphsBySpeakers(tmpWords, speakerSegmentation);\r\n  }\r\n\r\n  wordsByParagraphs.forEach((paragraph, i) => {\r\n    // if paragraph contain words\r\n    // eg sometimes the speaker segmentation might not contain words :man-shrugging:\r\n    if (paragraph.words[0] !== undefined) {\r\n      let speakerLabel = `TBC ${ i }`;\r\n      if (speakerSegmentation !== null) {\r\n        speakerLabel = paragraph.speaker;\r\n      }\r\n\r\n      const draftJsContentBlockParagraph = {\r\n        text: paragraph.text,\r\n        type: 'paragraph',\r\n        data: {\r\n          speaker: speakerLabel,\r\n          words: paragraph.words,\r\n          start: paragraph.words[0].start\r\n        },\r\n        // the entities as ranges are each word in the space-joined text,\r\n        // so it needs to be compute for each the offset from the beginning of the paragraph and the length\r\n        entityRanges: generateEntitiesRanges(paragraph.words, 'punct') // wordAttributeName\r\n      };\r\n      results.push(draftJsContentBlockParagraph);\r\n    }\r\n  });\r\n\r\n  return results;\r\n};\r\n\r\nexport default bbcKaldiToDraft;\r\n","/**\r\n * Convert autoEdit2 Json to draftJS\r\n * see `sample` folder for example of input and output as well as `example-usage.js`\r\n */\r\n\r\nimport generateEntitiesRanges from '../generate-entities-ranges/index';\r\n\r\n/**\r\n * groups words list from autoEdit transcript based on punctuation.\r\n * @todo To be more accurate, should introduce an honorifics library to do the splitting of the words.\r\n * @param {array} words - array of words objects from autoEdit transcript\r\n */\r\n\r\nconst groupWordsInParagraphs = (autoEditText) => {\r\n  const results = [];\r\n  let paragraph = { words: [], text: [] };\r\n\r\n  autoEditText.forEach((autoEditparagraph) => {\r\n    autoEditparagraph.paragraph.forEach((autoEditLine) => {\r\n      autoEditLine.line.forEach((word) => {\r\n        // adjusting time reference attributes from\r\n        // `startTime` `endTime` to `start` `end`\r\n        // for word object\r\n        const tmpWord = {\r\n          text: word.text,\r\n          start: word.startTime,\r\n          end: word.endTime,\r\n        };\r\n        //  if word contains punctuation\r\n        if (/[.?!]/.test(word.text)) {\r\n          paragraph.words.push(tmpWord);\r\n          paragraph.text.push(word.text);\r\n          results.push(paragraph);\r\n          // reset paragraph\r\n          paragraph = { words: [], text: [] };\r\n        } else {\r\n          paragraph.words.push(tmpWord);\r\n          paragraph.text.push(word.text);\r\n        }\r\n      });\r\n    });\r\n  });\r\n\r\n  return results;\r\n};\r\n\r\nconst autoEdit2ToDraft = (autoEdit2Json) => {\r\n  const results = [];\r\n  const tmpWords = autoEdit2Json.text;\r\n  const wordsByParagraphs = groupWordsInParagraphs(tmpWords);\r\n\r\n  wordsByParagraphs.forEach((paragraph, i) => {\r\n    const draftJsContentBlockParagraph = {\r\n      text: paragraph.text.join(' '),\r\n      type: 'paragraph',\r\n      data: {\r\n        speaker: `TBC ${ i }`,\r\n        words: paragraph.words,\r\n        start: paragraph.words[0].start\r\n      },\r\n      // the entities as ranges are each word in the space-joined text,\r\n      // so it needs to be compute for each the offset from the beginning of the paragraph and the length\r\n      entityRanges: generateEntitiesRanges(paragraph.words, 'text'),\r\n    };\r\n    // console.log(JSON.stringify(draftJsContentBlockParagraph,null,2))\r\n    results.push(draftJsContentBlockParagraph);\r\n  });\r\n\r\n  // console.log(JSON.stringify(results,null,2))\r\n  return results;\r\n};\r\n\r\nexport default autoEdit2ToDraft;\r\n","/**\r\n *  Convert Speechmatics Json to DraftJs\r\n *  see `sample` folder for example of input and output as well as `example-usage.js`\r\n */\r\n\r\nimport generateEntitiesRanges from '../generate-entities-ranges/index.js';\r\n\r\n/**\r\n * Determines the speaker of a paragraph by comparing the start time of the paragraph with\r\n * the speaker times.\r\n * @param {float} start - Starting point of paragraph\r\n * @param {array} speakers - list of all speakers with start and end time\r\n */\r\nconst getSpeaker = (start, speakers) => {\r\n  for (var speakerIdx in speakers) {\r\n    const speaker = speakers[speakerIdx];\r\n    const segmentStart = parseFloat(start);\r\n    if (segmentStart >= speaker.start & segmentStart < speaker.end) {\r\n      return speaker.name;\r\n    }\r\n  }\r\n\r\n  return 'UNK';\r\n};\r\n\r\n/**\r\n * groups words list from speechmatics based on speaker change and paragraph length.\r\n * @param {array} words - array of words objects from speechmatics transcript\r\n * @param {array} speakers - array of speaker objects from speechmatics transcript\r\n * @param {int} words - number of words which trigger a paragraph break\r\n */\r\nconst groupWordsInParagraphs = (words, speakers, maxParagraphWords) => {\r\n  const results = [];\r\n  let paragraph = { words: [], text: [], speaker: '' };\r\n  let oldSpeaker = getSpeaker(words[0].start, speakers);\r\n  let newSpeaker;\r\n  let sentenceEnd = false;\r\n\r\n  words.forEach((word) => {\r\n    newSpeaker = getSpeaker(word.start, speakers);\r\n    // if speaker changes\r\n    if (newSpeaker !== oldSpeaker || (paragraph.words.length > maxParagraphWords && sentenceEnd)) {\r\n      paragraph.speaker = oldSpeaker;\r\n      results.push(paragraph);\r\n      oldSpeaker = newSpeaker;\r\n      // reset paragraph\r\n      paragraph = { words: [], text: [] };\r\n    }\r\n    paragraph.words.push(word);\r\n    paragraph.text.push(word.punct);\r\n    sentenceEnd = /[.?!]/.test(word.punct) ? true : false;\r\n  });\r\n\r\n  paragraph.speaker = oldSpeaker;\r\n  results.push(paragraph);\r\n\r\n  return results;\r\n};\r\n\r\n/**\r\n * Speechmatics treats punctuation as own words. This function merges punctuations with\r\n * the pevious word and adjusts the total duration of the word.\r\n * @param {array} words - array of words objects from speechmatics transcript\r\n */\r\nconst curatePunctuation = (words) => {\r\n  const curatedWords = [];\r\n  words.forEach((word) => {\r\n    if (/[.?!,]/.test(word.name) && word.name.length == 1 && curatedWords.length > 0) {\r\n      curatedWords[curatedWords.length - 1].name = curatedWords[curatedWords.length - 1].name + word.name;\r\n      curatedWords[curatedWords.length - 1].duration = (parseFloat(curatedWords[curatedWords.length - 1].duration) + parseFloat(word.duration)).toString();\r\n    } else {\r\n      curatedWords.push(word);\r\n    }\r\n  }\r\n  );\r\n\r\n  return curatedWords;\r\n};\r\n\r\nconst speechmaticsToDraft = (speechmaticsJson) => {\r\n  const results = [];\r\n\r\n  let tmpWords;\r\n  tmpWords = curatePunctuation(speechmaticsJson.words);\r\n  tmpWords = tmpWords.map((element, index) => {\r\n    return ({\r\n      start: element.time,\r\n      end: (parseFloat(element.time) + parseFloat(element.duration)).toString(),\r\n      confidence: element.confidence,\r\n      word: element.name.toLowerCase().replace(/[.?!]/g, ''),\r\n      punct: element.name,\r\n      index: index,\r\n    });\r\n  });\r\n\r\n  let tmpSpeakers;\r\n  tmpSpeakers = speechmaticsJson.speakers;\r\n  tmpSpeakers = tmpSpeakers.map((element) => {\r\n    return ({\r\n      start: parseFloat(element.time),\r\n      end: (parseFloat(element.time) + parseFloat(element.duration)),\r\n      name: element.name,\r\n    });\r\n  });\r\n\r\n  const wordsByParagraphs = groupWordsInParagraphs(tmpWords, tmpSpeakers, 150);\r\n\r\n  wordsByParagraphs.forEach((paragraph) => {\r\n    const paragraphStart = paragraph.words[0].start;\r\n    const draftJsContentBlockParagraph = {\r\n      text: paragraph.text.join(' '),\r\n      type: 'paragraph',\r\n      data: {\r\n        speaker: paragraph.speaker,\r\n        words: paragraph.words,\r\n        start: paragraphStart\r\n      },\r\n      // the entities as ranges are each word in the space-joined text,\r\n      // so it needs to be compute for each the offset from the beginning of the paragraph and the length\r\n      entityRanges: generateEntitiesRanges(paragraph.words, 'punct'), // wordAttributeName\r\n    };\r\n    results.push(draftJsContentBlockParagraph);\r\n  });\r\n\r\n  return results;\r\n};\r\n\r\nexport default speechmaticsToDraft;\r\n","export const groupWordsBySpeakerLabel = (words) => {\r\n  const groupedWords = [];\r\n  let currentSpeaker = '';\r\n  words.forEach((word) => {\r\n    if (word.speaker_label === currentSpeaker) {\r\n      groupedWords[groupedWords.length - 1].words.push(word);\r\n    } else {\r\n      currentSpeaker = word.speaker_label;\r\n      // start new speaker block\r\n      groupedWords.push({\r\n        speaker: word.speaker_label,\r\n        words: [ word ] });\r\n    }\r\n  });\r\n\r\n  return groupedWords;\r\n};\r\n\r\nexport const findSpeakerForWord = (word, segments) => {\r\n  const startTime = parseFloat(word.start_time);\r\n  const endTime = parseFloat(word.end_time);\r\n  const firstMatchingSegment = segments.find((seg) => {\r\n    return startTime >= parseFloat(seg.start_time) && endTime <= parseFloat(seg.end_time);\r\n  });\r\n  if (firstMatchingSegment === undefined) {\r\n    return 'UKN';\r\n  } else {\r\n    return firstMatchingSegment.speaker_label.replace('spk_', '');\r\n  }\r\n};\r\n\r\nconst addSpeakerLabelToWords = (words, segments) => {\r\n  return words.map(w => Object.assign(w, { 'speaker_label': findSpeakerForWord(w, segments) }));\r\n};\r\n\r\nexport const groupWordsBySpeaker = (words, speakerLabels) => {\r\n  const wordsWithSpeakers = addSpeakerLabelToWords(words, speakerLabels.segments);\r\n\r\n  return groupWordsBySpeakerLabel(wordsWithSpeakers);\r\n};","/**\r\n * Converts AWS Transcribe Json to DraftJs\r\n * see `sample` folder for example of input and output as well as `example-usage.js`\r\n */\r\n\r\nimport generateEntitiesRanges from '../generate-entities-ranges/index.js';\r\nimport { groupWordsBySpeaker } from './group-words-by-speakers';\r\n\r\nexport const stripLeadingSpace = word => {\r\n  return word.replace(/^\\s/, '');\r\n};\r\n\r\n/**\r\n *  @param {json} words  - List of words\r\n *  @param {string} wordAttributeName - eg 'punct' or 'text' or etc.\r\n * attribute for the word object containing the text. eg word ={ punct:'helo', ... }\r\n *  or eg word ={ text:'helo', ... }\r\n */\r\nexport const getBestAlternativeForWord = word => {\r\n  if (/punctuation/.test(word.type)) {\r\n    return Object.assign(word.alternatives[0], { confidence: 1 }); //Transcribe doesn't provide a confidence for punctuation\r\n  }\r\n  const wordWithHighestConfidence = word.alternatives.reduce(function(\r\n    prev,\r\n    current\r\n  ) {\r\n    return parseFloat(prev.confidence) > parseFloat(current.confidence)\r\n      ? prev\r\n      : current;\r\n  });\r\n\r\n  return wordWithHighestConfidence;\r\n};\r\n\r\n/**\r\n * Normalizes words so they can be used in\r\n * the generic generateEntitiesRanges() method\r\n **/\r\nconst normalizeWord = currentWord => {\r\n  const bestAlternative = getBestAlternativeForWord(currentWord);\r\n\r\n  return {\r\n    start: parseFloat(currentWord.start_time),\r\n    end: parseFloat(currentWord.end_time),\r\n    text: bestAlternative.content,\r\n    confidence: parseFloat(bestAlternative.confidence)\r\n  };\r\n};\r\n\r\nexport const appendPunctuationToPreviousWord = (punctuation, previousWord) => {\r\n  const punctuationContent = punctuation.alternatives[0].content;\r\n\r\n  return {\r\n    ...previousWord,\r\n    alternatives: previousWord.alternatives.map(w => ({\r\n      ...w,\r\n      content: w.content + stripLeadingSpace(punctuationContent)\r\n    }))\r\n  };\r\n};\r\n\r\nexport const mapPunctuationItemsToWords = words => {\r\n  const itemsToRemove = [];\r\n  const dirtyArray = words.map((word, index) => {\r\n    let previousWord = {};\r\n    if (word.type === 'punctuation') {\r\n      itemsToRemove.push(index - 1);\r\n      previousWord = words[index - 1];\r\n\r\n      return appendPunctuationToPreviousWord(word, previousWord);\r\n    } else {\r\n      return word;\r\n    }\r\n  });\r\n\r\n  return dirtyArray.filter((item, index) => {\r\n    return !itemsToRemove.includes(index);\r\n  });\r\n};\r\n\r\n/**\r\n * groups words list from amazon transcribe transcript based on punctuation.\r\n * @todo To be more accurate, should introduce an honorifics library to do the splitting of the words.\r\n * @param {array} words - array of words objects from kaldi transcript\r\n */\r\nconst groupWordsInParagraphs = words => {\r\n  const results = [];\r\n  let paragraph = {\r\n    words: [],\r\n    text: []\r\n  };\r\n  words.forEach((word) => {\r\n    const content = getBestAlternativeForWord(word).content;\r\n    const normalizedWord = normalizeWord(word);\r\n    if (/[.?!]/.test(content)) {\r\n      paragraph.words.push(normalizedWord);\r\n      paragraph.text.push(content);\r\n      results.push(paragraph);\r\n      // reset paragraph\r\n      paragraph = { words: [], text: [] };\r\n    } else {\r\n      paragraph.words.push(normalizedWord);\r\n      paragraph.text.push(content);\r\n    }\r\n  });\r\n\r\n  return results;\r\n};\r\n\r\nconst groupSpeakerWordsInParagraphs = (words, speakerLabels) => {\r\n  const wordsBySpeaker = groupWordsBySpeaker(words, speakerLabels);\r\n\r\n  return wordsBySpeaker.map((speakerGroup) => {\r\n    return {\r\n      words: speakerGroup.words.map(normalizeWord),\r\n      text: speakerGroup.words.map((w) => getBestAlternativeForWord(w).content),\r\n      speaker: speakerGroup.speaker\r\n    };\r\n  });\r\n};\r\n\r\nconst amazonTranscribeToDraft = amazonTranscribeJson => {\r\n  const results = [];\r\n  const tmpWords = amazonTranscribeJson.results.items;\r\n  const speakerLabels = amazonTranscribeJson.results.speaker_labels;\r\n  const wordsWithRemappedPunctuation = mapPunctuationItemsToWords(tmpWords);\r\n  const speakerSegmentation = typeof(speakerLabels) != 'undefined';\r\n\r\n  const wordsByParagraphs = speakerSegmentation ?\r\n    groupSpeakerWordsInParagraphs(wordsWithRemappedPunctuation, speakerLabels) :\r\n    groupWordsInParagraphs(\r\n      wordsWithRemappedPunctuation\r\n    );\r\n\r\n  wordsByParagraphs.forEach((paragraph, i) => {\r\n    const draftJsContentBlockParagraph = {\r\n      text: paragraph.text.join(' '),\r\n      type: 'paragraph',\r\n      data: {\r\n        speaker: paragraph.speaker ? `Speaker ${ paragraph.speaker }` : `TBC ${ i }`,\r\n        words: paragraph.words,\r\n        start: parseFloat(paragraph.words[0].start)\r\n      },\r\n      // the entities as ranges are each word in the space-joined text,\r\n      // so it needs to be compute for each the offset from the beginning of the paragraph and the length\r\n      entityRanges: generateEntitiesRanges(paragraph.words, 'text') // wordAttributeName\r\n    };\r\n    results.push(draftJsContentBlockParagraph);\r\n  });\r\n\r\n  return results;\r\n};\r\n\r\nexport default amazonTranscribeToDraft;\r\n","/**\r\n * Convert IBM json to draftJS\r\n * see `sample` folder for example of input and output as well as `example-usage.js`\r\n *\r\n */\r\nimport generateEntitiesRanges from '../generate-entities-ranges/index.js';\r\n\r\nconst ibmToDraft = ibmJson => {\r\n  // helper function to normalise IBM words at line level\r\n  const normalizeTimeStampsToWords = timestamps => {\r\n    return timestamps.map(ibmWord => {\r\n      return {\r\n        text: ibmWord[0],\r\n        start: ibmWord[1],\r\n        end: ibmWord[2]\r\n      };\r\n    });\r\n  };\r\n\r\n  //\r\n  const normalizeIBMWordsList = ibmResults => {\r\n    const normalisedResults = [];\r\n    ibmResults.forEach(result => {\r\n      // nested array to keep paragraph segmentation same as IBM lines\r\n      normalisedResults.push(normalizeTimeStampsToWords(result.alternatives[0].timestamps));\r\n      // TODO: can be revisited - as separate PR by flattening the array like this\r\n      // normalisedResults = normalisedResults.concact(normalizeTimeStampsToWords(result.alternatives[0].timestamps));\r\n      // addSpeakersToWords function would need adjusting as would be dealing with a 1D array instead of 2D\r\n      // if edge case, like in example file, that there's one speaker recognised through all of speaker segemtnation info\r\n      // could break into paragraph when is over a minute? at end of IBM line?\r\n      // or punctuation, altho IBM does not seem to provide punctuation?\r\n    });\r\n\r\n    return normalisedResults;\r\n  };\r\n\r\n  // TODO: could be separate file\r\n  const findSpeakerSegmentForWord = (word, speakerSegments) => {\r\n    const tmpSegment = speakerSegments.find(seg => {\r\n      const segStart = seg.from;\r\n      const segEnd = seg.to;\r\n\r\n      return ((word.start === segStart) && (word.end === segEnd));\r\n    });\r\n    // if find doesn't find any matches it returns an undefined\r\n    if (tmpSegment === undefined) {\r\n      // covering edge case orphan word not belonging to any segments\r\n      // adding UKN speaker label\r\n      return 'UKN';\r\n    } else {\r\n      // find returns the first element that matches the criteria\r\n      return `S_${ tmpSegment.speaker }`;\r\n    }\r\n  };\r\n  // add speakers to words\r\n  const addSpeakersToWords = (ibmWords, ibmSpeakers) => {\r\n    return ibmWords.map(lines => {\r\n      return lines.map(word => {\r\n\r\n        word.speaker = findSpeakerSegmentForWord(word, ibmSpeakers);\r\n\r\n        return word;\r\n      });\r\n    });\r\n  };\r\n\r\n  const ibmNormalisedWordsToDraftJs = (ibmNormalisedWordsWithSpeakers) => {\r\n    const draftJsParagraphsResults = [];\r\n    ibmNormalisedWordsWithSpeakers.forEach((ibmParagraph) => {\r\n      const draftJsContentBlockParagraph = {\r\n        text: ibmParagraph.map((word) => {return word.text;}).join(' '),\r\n        type: 'paragraph',\r\n        data: {\r\n          // Assuming each paragraph in IBM line is the same\r\n          // for context it just seems like the IBM data structure gives you word level speakers,\r\n          // but also gives you \"lines\" so assuming each word in a line has the same speaker.\r\n          speaker: ibmParagraph[0].speaker,\r\n          words: ibmParagraph,\r\n          start: ibmParagraph[0].start\r\n        },\r\n        // the entities as ranges are each word in the space-joined text,\r\n        // so it needs to be compute for each the offset from the beginning of the paragraph and the length\r\n        entityRanges: generateEntitiesRanges(ibmParagraph, 'text'), // wordAttributeName\r\n      };\r\n      draftJsParagraphsResults.push(draftJsContentBlockParagraph);\r\n    });\r\n\r\n    return draftJsParagraphsResults;\r\n  };\r\n\r\n  const normalisedWords = normalizeIBMWordsList(ibmJson.results[0].results);\r\n  // TODO: nested array of words, to keep some sort of paragraphs, in case there's only one speaker\r\n  // can be refactored/optimised later\r\n  const ibmNormalisedWordsWithSpeakers = addSpeakersToWords(normalisedWords, ibmJson.results[0].speaker_labels);\r\n  const ibmDratJs = ibmNormalisedWordsToDraftJs(ibmNormalisedWordsWithSpeakers);\r\n\r\n  return ibmDratJs;\r\n};\r\n\r\nexport default ibmToDraft;\r\n","/**\r\n * Convert Digital Paper Edit transcript json format to DraftJS\r\n * More details see\r\n * https://github.com/bbc/digital-paper-edit\r\n */\r\nimport generateEntitiesRanges from '../generate-entities-ranges/index.js';\r\nimport groupWordsInParagraphsBySpeakers from './group-words-by-speakers.js';\r\n/**\r\n * groups words list from kaldi transcript based on punctuation.\r\n * @todo To be more accurate, should introduce an honorifics library to do the splitting of the words.\r\n * @param {array} words - array of words opbjects from kaldi transcript\r\n */\r\nconst groupWordsInParagraphs = words => {\r\n  const results = [];\r\n  let paragraph = { words: [], text: [] };\r\n\r\n  words.forEach(word => {\r\n    // if word contains punctuation\r\n    if (/[.?!]/.test(word.text)) {\r\n      paragraph.words.push(word);\r\n      paragraph.text.push(word.text);\r\n      paragraph.text = paragraph.text.join(' ');\r\n      results.push(paragraph);\r\n      // reset paragraph\r\n      paragraph = { words: [], text: [] };\r\n    } else {\r\n      paragraph.words.push(word);\r\n      paragraph.text.push(word.text);\r\n    }\r\n  });\r\n\r\n  return results;\r\n};\r\n\r\nconst digitalPaperEditToDraft = (digitalPaperEditTranscriptJson) => {\r\n  const results = [];\r\n  let speakerSegmentation = null;\r\n  let wordsByParagraphs = [];\r\n  const tmpWords = digitalPaperEditTranscriptJson.words;\r\n\r\n  if (digitalPaperEditTranscriptJson.paragraphs) {\r\n    speakerSegmentation = digitalPaperEditTranscriptJson.paragraphs;\r\n  }\r\n\r\n  if (!speakerSegmentation) {\r\n    wordsByParagraphs = groupWordsInParagraphs(tmpWords);\r\n  } else {\r\n    wordsByParagraphs = groupWordsInParagraphsBySpeakers(tmpWords, digitalPaperEditTranscriptJson.paragraphs );\r\n  }\r\n\r\n  wordsByParagraphs.forEach((paragraph, i) => {\r\n    // if paragraph contain words\r\n    // eg sometimes the speaker segmentation might not contain words :man-shrugging:\r\n    if (paragraph.words[0]) {\r\n      let speakerLabel = `TBC ${ i }`;\r\n      if (speakerSegmentation) {\r\n        speakerLabel = paragraph.speaker;\r\n      }\r\n\r\n      const draftJsContentBlockParagraph = {\r\n        text: paragraph.text,\r\n        type: 'paragraph',\r\n        data: {\r\n          speaker: speakerLabel,\r\n          words: paragraph.words,\r\n          start: paragraph.words[0].start\r\n        },\r\n        // the entities as ranges are each word in the space-joined text,\r\n        // so it needs to be compute for each the offset from the beginning of the paragraph and the length\r\n        entityRanges: generateEntitiesRanges(paragraph.words, 'text') // wordAttributeName\r\n      };\r\n      results.push(draftJsContentBlockParagraph);\r\n    }\r\n  });\r\n\r\n  return results;\r\n};\r\n\r\nexport default digitalPaperEditToDraft;\r\n","/**\r\n * Helper function to generate draft.js entityMap from draftJS blocks,\r\n */\r\n\r\n/**\r\n * helper function to flatten a list.\r\n * converts nested arrays into one dimensional array\r\n * @param {array} list\r\n */\r\nconst flatten = list => list.reduce((a, b) => a.concat(Array.isArray(b) ? flatten(b) : b), []);\r\n\r\n/**\r\n * helper function to create createEntityMap\r\n * @param {*} blocks - draftJs blocks\r\n */\r\nconst createEntityMap = (blocks) => {\r\n  const entityRanges = blocks.map(block => block.entityRanges);\r\n  const flatEntityRanges = flatten(entityRanges);\r\n\r\n  const entityMap = {};\r\n\r\n  flatEntityRanges.forEach((data) => {\r\n    entityMap[data.key] = {\r\n      type: 'WORD',\r\n      mutability: 'MUTABLE',\r\n      data,\r\n    };\r\n  });\r\n\r\n  return entityMap;\r\n};\r\n\r\nexport default createEntityMap;","/**\r\n * Converts GCP Speech to Text Json to DraftJs\r\n * see `sample` folder for example of input and output as well as `example-usage.js`\r\n */\r\n\r\nimport generateEntitiesRanges from '../generate-entities-ranges/index.js';\r\n\r\nconst NANO_SECOND = 1000000000;\r\n\r\n/**\r\n * attribute for the sentences object containing the text. eg sentences ={ punct:'helo', ... }\r\n *  or eg sentences ={ text:'hello', ... }\r\n * @param sentences\r\n */\r\nexport const getBestAlternativeSentence = sentences => {\r\n  if (sentences.alternatives.length === 0) {\r\n    return sentences[0];\r\n  }\r\n\r\n  const sentenceWithHighestConfidence = sentences.alternatives.reduce(function(\r\n    prev,\r\n    current\r\n  ) {\r\n    return parseFloat(prev.confidence) > parseFloat(current.confidence)\r\n      ? prev\r\n      : current;\r\n  });\r\n\r\n  return sentenceWithHighestConfidence;\r\n};\r\n\r\nexport const trimLeadingAndTailingWhiteSpace = text => {\r\n  return text.trim();\r\n};\r\n\r\n/**\r\n * GCP does not provide a nanosecond attribute if the word starts at 0 nanosecond\r\n * @param startSecond\r\n * @param nanoSecond\r\n * @returns {number}\r\n */\r\nconst computeTimeInSeconds = (startSecond, nanoSecond) => {\r\n\r\n  let seconds = parseFloat(startSecond);\r\n\r\n  if (nanoSecond !== undefined) {\r\n    seconds = seconds + parseFloat(nanoSecond / NANO_SECOND);\r\n  }\r\n\r\n  return seconds;\r\n};\r\n\r\n/**\r\n * Normalizes words so they can be used in\r\n * the generic generateEntitiesRanges() method\r\n **/\r\nconst normalizeWord = (currentWord, confidence) => {\r\n\r\n  return {\r\n    start: computeTimeInSeconds(currentWord.startTime.seconds, currentWord.startTime.nanos),\r\n    end: computeTimeInSeconds(currentWord.endTime.seconds, currentWord.endTime.nanos),\r\n    text: currentWord.word,\r\n    confidence: confidence\r\n  };\r\n};\r\n\r\n/**\r\n * groups words list from GCP Speech to Text response.\r\n * @param {array} sentences - array of sentence objects from GCP STT\r\n */\r\nconst groupWordsInParagraphs = sentences => {\r\n  const results = [];\r\n  let paragraph = {\r\n    words: [],\r\n    text: []\r\n  };\r\n\r\n  sentences.forEach((sentence) => {\r\n    const bestAlternative = getBestAlternativeSentence(sentence);\r\n    paragraph.text.push(trimLeadingAndTailingWhiteSpace(bestAlternative.transcript));\r\n\r\n    bestAlternative.words.forEach((word) => {\r\n      paragraph.words.push(normalizeWord(word, bestAlternative.confidence));\r\n    });\r\n    results.push(paragraph);\r\n    paragraph = { words: [], text: [] };\r\n  });\r\n\r\n  return results;\r\n};\r\n\r\nconst gcpSttToDraft = gcpSttJson => {\r\n  const results = [];\r\n  // const speakerLabels = gcpSttJson.results[0]['alternatives'][0]['words'][0]['speakerTag']\r\n  // let speakerSegmentation = typeof(speakerLabels) != 'undefined';\r\n\r\n  const wordsByParagraphs = groupWordsInParagraphs(gcpSttJson.results);\r\n\r\n  wordsByParagraphs.forEach((paragraph, i) => {\r\n    const draftJsContentBlockParagraph = {\r\n      text: paragraph.text.join(' '),\r\n      type: 'paragraph',\r\n      data: {\r\n        speaker: paragraph.speaker ? `Speaker ${ paragraph.speaker }` : `TBC ${ i }`,\r\n        words: paragraph.words,\r\n        start: parseFloat(paragraph.words[0].start)\r\n      },\r\n      // the entities as ranges are each word in the space-joined text,\r\n      // so it needs to be compute for each the offset from the beginning of the paragraph and the length\r\n      entityRanges: generateEntitiesRanges(paragraph.words, 'text') // wordAttributeName\r\n    };\r\n    results.push(draftJsContentBlockParagraph);\r\n  });\r\n\r\n  return results;\r\n};\r\n\r\nexport default gcpSttToDraft;\r\n","import bbcKaldiToDraft from './bbc-kaldi/index';\r\nimport autoEdit2ToDraft from './autoEdit2/index';\r\nimport speechmaticsToDraft from './speechmatics/index';\r\nimport amazonTranscribeToDraft from './amazon-transcribe/index';\r\nimport ibmToDraft from './ibm/index';\r\nimport digitalPaperEditToDraft from './digital-paper-edit/index';\r\nimport createEntityMap from './create-entity-map/index';\r\nimport gcpSttToDraft from './google-stt/index';\r\n\r\n/**\r\n * Adapters for STT conversion\r\n * @param {json} transcriptData - A json transcript with some word accurate timecode\r\n * @param {string} sttJsonType - the type of transcript supported by the available adapters\r\n */\r\nconst sttJsonAdapter = (transcriptData, sttJsonType) => {\r\n  let blocks;\r\n  switch (sttJsonType) {\r\n  case 'bbckaldi':\r\n    blocks = bbcKaldiToDraft(transcriptData);\r\n\r\n    return { blocks, entityMap: createEntityMap(blocks) };\r\n  case 'autoedit2':\r\n    blocks = autoEdit2ToDraft(transcriptData);\r\n\r\n    return { blocks, entityMap: createEntityMap(blocks) };\r\n  case 'speechmatics':\r\n    blocks = speechmaticsToDraft(transcriptData);\r\n\r\n    return { blocks, entityMap: createEntityMap(blocks) };\r\n  case 'ibm':\r\n    blocks = ibmToDraft(transcriptData);\r\n\r\n    return { blocks, entityMap: createEntityMap(blocks) };\r\n  case 'draftjs':\r\n    return transcriptData; // (typeof transcriptData === 'string')? JSON.parse(transcriptData): transcriptData;\r\n\r\n  case 'amazontranscribe':\r\n    blocks = amazonTranscribeToDraft(transcriptData);\r\n\r\n    return { blocks, entityMap: createEntityMap(blocks) };\r\n  case 'digitalpaperedit':\r\n    blocks = digitalPaperEditToDraft(transcriptData);\r\n\r\n    return { blocks, entityMap: createEntityMap(blocks) };\r\n\r\n  case 'google-stt':\r\n    blocks = gcpSttToDraft(transcriptData);\r\n\r\n    return { blocks, entityMap: createEntityMap(blocks) };\r\n\r\n  default:\r\n    // code block\r\n    console.error('Did not recognize the stt engine.');\r\n  }\r\n};\r\n\r\nexport default sttJsonAdapter;\r\nexport { createEntityMap };","/**\r\n edge cases\r\n- more segments then words - not an issue if you start by matching words with segment\r\nand handle edge case where it doesn't find a match\r\n- more words then segments - orphan words?\r\n*\r\n* Takes in list of words and list of paragraphs (paragraphs have speakers info associated with it)\r\n```js\r\n{\r\n  \"words\": [\r\n    {\r\n      \"id\": 0,\r\n      \"start\": 13.02,\r\n      \"end\": 13.17,\r\n      \"text\": \"There\"\r\n    },\r\n    {\r\n      \"id\": 1,\r\n      \"start\": 13.17,\r\n      \"end\": 13.38,\r\n      \"text\": \"is\"\r\n    },\r\n    ...\r\n    ],\r\n  \"paragraphs\": [\r\n    {\r\n      \"id\": 0,\r\n      \"start\": 13.02,\r\n      \"end\": 13.86,\r\n      \"speaker\": \"TBC 00\"\r\n    },\r\n    {\r\n      \"id\": 1,\r\n      \"start\": 13.86,\r\n      \"end\": 19.58,\r\n      \"speaker\": \"TBC 1\"\r\n    },\r\n    ...\r\n  ]\r\n}\r\n```\r\n*  and returns a list of words grouped into paragraphs, with words, text and speaker attribute\r\n```js\r\n[\r\n  {\r\n    \"words\": [\r\n      {\r\n        \"id\": 0,\r\n        \"start\": 13.02,\r\n        \"end\": 13.17,\r\n        \"text\": \"There\"\r\n      },\r\n      {\r\n        \"id\": 1,\r\n        \"start\": 13.17,\r\n        \"end\": 13.38,\r\n        \"text\": \"is\"\r\n      },\r\n      {\r\n        \"id\": 2,\r\n        \"start\": 13.38,\r\n        \"end\": 13.44,\r\n        \"text\": \"a\"\r\n      },\r\n      {\r\n        \"id\": 3,\r\n        \"start\": 13.44,\r\n        \"end\": 13.86,\r\n        \"text\": \"day.\"\r\n      }\r\n    ],\r\n    \"text\": \"There is a day.\",\r\n    \"speaker\": \"TBC 00\"\r\n  },\r\n  ...\r\n]\r\n```\r\n */\r\nfunction groupWordsInParagraphsBySpeakers(words, segments) {\r\n  const result = addWordsToSpeakersParagraphs(words, segments);\r\n\r\n  return result;\r\n};\r\n\r\nfunction addWordsToSpeakersParagraphs (words, segments) {\r\n  const results = [];\r\n  let currentSegment = 'UKN';\r\n  let currentSegmentIndex = 0;\r\n  let previousSegmentIndex = 0;\r\n  let paragraph = { words: [], text: '', speaker: '' };\r\n  words.forEach((word) => {\r\n    currentSegment = findSegmentForWord(word, segments);\r\n    // if a segment exists for the word\r\n    if (currentSegment) {\r\n      currentSegmentIndex = segments.indexOf(currentSegment);\r\n      if (currentSegmentIndex === previousSegmentIndex) {\r\n        paragraph.words.push(word);\r\n        paragraph.text += word.text + ' ';\r\n        paragraph.speaker = currentSegment.speaker;\r\n      }\r\n      else {\r\n        previousSegmentIndex = currentSegmentIndex;\r\n        paragraph.text.trim();\r\n        results.push(paragraph);\r\n        paragraph = { words: [], text: '', speaker: '' };\r\n        paragraph.words.push(word);\r\n        paragraph.text += word.text + ' ';\r\n        paragraph.speaker = currentSegment.speaker;\r\n      }\r\n    }\r\n  });\r\n  results.push(paragraph);\r\n\r\n  return results;\r\n}\r\n\r\n/**\r\n* Helper functions\r\n*/\r\n\r\n/**\r\n* given word start and end time attributes\r\n* looks for segment range that contains that word\r\n* if it doesn't find any it returns a segment with `UKN`\r\n* speaker attributes.\r\n* @param {object} word - word object\r\n* @param {array} segments - list of segments objects\r\n* @return {object} - a single segment whose range contains the word\r\n*/\r\nfunction findSegmentForWord(word, segments) {\r\n\r\n  const tmpSegment = segments.find((seg) => {\r\n    if ((word.start >= seg.start) && (word.end <= seg.end)) {\r\n      return seg;\r\n    }\r\n  });\r\n\r\n  return tmpSegment;\r\n}\r\n\r\nexport default groupWordsInParagraphsBySpeakers;"],"sourceRoot":""}